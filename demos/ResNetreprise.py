#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import math
from pathlib import Path
from typing import Tuple, Optional, Dict, List

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms, models
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# =========================
# CONFIG
# =========================
DATA_DIR = "/Users/a.cariven/Documents/USAFA/comp scien/final-project-aymeric-et-louis/demos/crop"  # doit contenir train/ et val/ ou un seul dossier (split auto)
EPOCHS = 5
BATCH_SIZE = 64
NUM_WORKERS = 8
IMAGE_SIZE = 128
BASE_LR = 1e-3
WEIGHT_DECAY = 1e-4
VAL_SPLIT = 0.15            # utilis√© seulement si pas de dossier val/
EARLY_STOP_PATIENCE = 10    # patience en √©poques, sur la val_loss
GRAD_CLIP_NORM = 1.0

# Scheduler plateau par it√©ration
PLATEAU_FACTOR = 0.5        # multiplicateur LR quand on r√©duit
PLATEAU_PATIENCE = 3        # it√©rations cons√©cutives sans am√©lioration
PLATEAU_THRESHOLD = 1e-4    # am√©lioration relative minimale
PLATEAU_MIN_LR = 1e-7
PLATEAU_COOLDOWN = 0        # it√©rations apr√®s r√©duction durant lesquelles on n‚Äôapplique plus de r√©duction

# Lissage EMA optionnel de la loss (pour scheduler)
USE_EMA = True
EMA_ALPHA = 0.1             # plus petit = plus lisse

# Checkpoints (state_dict l√©gers)
CKPT_DIR = "./checkpoints"
CKPT_BEST = os.path.join(CKPT_DIR, "ckpt_best_light.pth")
CKPT_LAST = "/Users/a.cariven/Documents/USAFA/comp scien/final-project-aymeric-et-louis/resnet_model_optimized.pth"
RESUME_FROM = CKPT_LAST 

SEED = 42

# =========================
# UTILS
# =========================
def set_seed(seed: int = 42):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

def get_device() -> torch.device:
    if torch.cuda.is_available():
        return torch.device("cuda")
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        return torch.device("mps")
    return torch.device("cpu")

def imagenet_transforms(img_size: int) -> Tuple[transforms.Compose, transforms.Compose]:
    train_tf = transforms.Compose([
        transforms.RandomResizedCrop(img_size, scale=(0.6, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])
    val_tf = transforms.Compose([
        transforms.Resize(int(img_size * 1.15)),
        transforms.CenterCrop(img_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])
    return train_tf, val_tf

def build_datasets(data_dir: str, img_size: int, val_split: float) -> Tuple[torch.utils.data.Dataset, torch.utils.data.Dataset, List[str]]:
    train_tf, val_tf = imagenet_transforms(img_size)

    # Cas 1: data_dir contient "train" et "val"
    train_dir = os.path.join(data_dir, "train")
    val_dir = os.path.join(data_dir, "val")
    if os.path.isdir(train_dir) and os.path.isdir(val_dir):
        train_ds = datasets.ImageFolder(train_dir, transform=train_tf)
        val_ds = datasets.ImageFolder(val_dir, transform=val_tf)
        classes = train_ds.classes
        return train_ds, val_ds, classes

    # Cas 2: split automatique depuis un seul dossier
    full_ds = datasets.ImageFolder(data_dir, transform=train_tf)
    n_total = len(full_ds)
    n_val = int(n_total * val_split)
    n_train = n_total - n_val
    train_ds, val_ds = random_split(full_ds, [n_train, n_val],
                                    generator=torch.Generator().manual_seed(SEED))
    # Important: val doit utiliser val_tf (remplace transform du sous-dataset)
    val_ds.dataset = datasets.ImageFolder(data_dir, transform=val_tf)
    classes = full_ds.classes
    return train_ds, val_ds, classes

def build_dataloaders(train_ds, val_ds, batch_size: int, num_workers: int) -> Tuple[DataLoader, DataLoader]:
    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,
                          num_workers=num_workers, pin_memory=True, drop_last=False)
    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False,
                        num_workers=num_workers, pin_memory=True, drop_last=False)
    return train_dl, val_dl

def build_model(num_classes: int) -> nn.Module:
    # ResNet18 pr√©-entra√Æn√©e ImageNet; on remplace la t√™te
    try:
        from torchvision.models import ResNet18_Weights
        weights = ResNet18_Weights.DEFAULT
        model = models.resnet18(weights=weights)
    except Exception:
        # fallback pour versions plus anciennes
        model = models.resnet18(pretrained=True)
    in_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(p=0.2),
        nn.Linear(in_features, num_classes)
    )
    return model

def accuracy(logits: torch.Tensor, target: torch.Tensor, topk=(1,)):
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)
        _, pred = logits.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))
        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size).item())
        return res

def save_light(path: str, model: nn.Module, optimizer: optim.Optimizer,
               epoch: int, best_val_loss: float, best_val_acc: float):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    torch.save({
        "model": model.state_dict(),
        "optimizer": optimizer.state_dict(),
        "epoch": epoch,
        "best_val_loss": best_val_loss,
        "best_val_acc": best_val_acc
    }, path)

def _looks_like_state_dict(obj) -> bool:
    if not isinstance(obj, dict): 
        return False
    # heuristique simple: au moins une cl√© de poids
    return any(isinstance(k, str) and (k.endswith(".weight") or ".running_mean" in k or ".bias" in k) 
               for k in obj.keys())

def load_light(path: str, model: nn.Module, optimizer: Optional[optim.Optimizer] = None,
               map_location: str = "cpu") -> dict:
    ckpt = torch.load(path, map_location=map_location)

    # 1) Cas: ckpt est directement un state_dict
    if _looks_like_state_dict(ckpt):
        model.load_state_dict(ckpt, strict=False)
        if optimizer is not None:
            # pas d‚Äôinfo optimizer disponible
            pass
        return {"epoch": 0, "best_val_loss": float("inf"), "best_val_acc": 0.0}

    if not isinstance(ckpt, dict):
        raise ValueError(f"Checkpoint inattendu: type={type(ckpt)}")

    # 2) Essayer plusieurs cl√©s possibles pour le mod√®le
    model_sd = None
    for k in ["model", "state_dict", "model_state_dict", "net", "module", "params"]:
        if k in ckpt and _looks_like_state_dict(ckpt[k]):
            model_sd = ckpt[k]
            break
    if model_sd is None:
        # dernier recours: peut-√™tre ckpt est un dict qui contient DIRECTEMENT les poids (ex: lightning avec prefix)
        # on filtre les cl√©s plausibles
        candidate = {k: v for k, v in ckpt.items() if isinstance(k, str) and _looks_like_state_dict({k: v})}
        if candidate:
            model_sd = candidate
    if model_sd is None:
        raise KeyError(f"Aucune cl√© de state_dict trouv√©e dans {path}. Cl√©s disponibles: {list(ckpt.keys())[:20]}")

    # Charger tol√©rant
    missing, unexpected = model.load_state_dict(model_sd, strict=False)
    if missing:
        print(f"‚ö†Ô∏è load_state_dict: missing keys (extrait): {missing[:10]}{' ...' if len(missing)>10 else ''}")
    if unexpected:
        print(f"‚ö†Ô∏è load_state_dict: unexpected keys (extrait): {unexpected[:10]}{' ...' if len(unexpected)>10 else ''}")

    # 3) Optimizer √©ventuel
    if optimizer is not None:
        opt_sd = None
        for k in ["optimizer", "optimizer_state_dict"]:
            if k in ckpt and isinstance(ckpt[k], dict):
                opt_sd = ckpt[k]
                break
        if opt_sd is not None:
            try:
                optimizer.load_state_dict(opt_sd)
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de charger l‚Äôoptimizer (on repart neuf): {e}")

    # 4) M√©tadonn√©es
    meta = {
        "epoch": ckpt.get("epoch", 0),
        "best_val_loss": ckpt.get("best_val_loss", float("inf")),
        "best_val_acc": ckpt.get("best_val_acc", 0.0)
    }
    return meta

# =========================
# Scheduler plateau par it√©ration
# =========================
class IterPlateau:
    def __init__(self, optimizer, factor=0.5, patience=3,
                 threshold=1e-4, threshold_mode="rel",
                 min_lr=1e-7, cooldown=0, verbose=True):
        self.optimizer = optimizer
        self.factor = factor
        self.patience = patience
        self.threshold = threshold
        self.threshold_mode = threshold_mode  # "rel" ou "abs"
        self.min_lr = min_lr
        self.cooldown = cooldown
        self.cooldown_counter = 0
        self.best = None
        self.num_bad = 0
        self.verbose = verbose

    def _is_better(self, loss, best):
        if best is None:
            return True
        if self.threshold_mode == "rel":
            return loss < best * (1 - self.threshold)
        else:
            return loss < best - self.threshold

    def _reduce_lr(self):
        changed = []
        for i, pg in enumerate(self.optimizer.param_groups):
            old_lr = float(pg["lr"])
            new_lr = max(old_lr * self.factor, self.min_lr)
            if new_lr < old_lr - 1e-16:
                pg["lr"] = new_lr
                changed.append((i, old_lr, new_lr))
        if self.verbose and changed:
            msg = " | ".join([f"group {i}: {old:.2e} -> {new:.2e}" for i, old, new in changed])
            print(f"‚ö†Ô∏è Reduce LR on plateau: {msg}")

    def step(self, loss_value: float):
        if self.cooldown_counter > 0:
            self.cooldown_counter -= 1

        if self._is_better(loss_value, self.best):
            self.best = loss_value
            self.num_bad = 0
        else:
            self.num_bad += 1
            if self.num_bad >= self.patience and self.cooldown_counter == 0:
                self._reduce_lr()
                self.num_bad = 0
                self.cooldown_counter = self.cooldown

# =========================
# EVAL
# =========================
def evaluate(model: nn.Module, dl: DataLoader, device: torch.device, criterion: nn.Module):
    model.eval()
    loss_sum = 0.0
    total = 0
    top1_sum = 0.0
    with torch.no_grad():
        for x, y in dl:
            x, y = x.to(device), y.to(device)
            logits = model(x)
            loss = criterion(logits, y)
            loss_sum += loss.item() * y.size(0)
            top1 = accuracy(logits, y, topk=(1,))[0]
            top1_sum += top1 * y.size(0) / 100.0
            total += y.size(0)
    return loss_sum / total, 100.0 * (top1_sum / total)

# =========================
# TRAIN
# =========================
def train():
    set_seed(SEED)
    device = get_device()
    print(f"Device: {device}")

    train_ds, val_ds, classes = build_datasets(DATA_DIR, IMAGE_SIZE, VAL_SPLIT)
    num_classes = len(classes)
    print(f"Classes ({num_classes}): {classes}")

    train_dl, val_dl = build_dataloaders(train_ds, val_ds, BATCH_SIZE, NUM_WORKERS)

    model = build_model(num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)

    # Scheduler plateau par it√©ration
    plateau = IterPlateau(
        optimizer,
        factor=PLATEAU_FACTOR,
        patience=PLATEAU_PATIENCE,
        threshold=PLATEAU_THRESHOLD,
        threshold_mode="rel",
        min_lr=PLATEAU_MIN_LR,
        cooldown=PLATEAU_COOLDOWN,
        verbose=True
    )

    # Reprise √©ventuelle
start_epoch = 0
best_val_loss = float("inf")
best_val_acc = 0.0
if RESUME_FROM and os.path.isfile(RESUME_FROM):
    meta = load_light(RESUME_FROM, models, optimizer, map_location="cpu")
    start_epoch = int(meta.get("epoch", 0)) + 1
    best_val_loss = float(meta.get("best_val_loss", float("inf")))
    best_val_acc = float(meta.get("best_val_acc", 0.0))
    print(f"Reprise depuis {RESUME_FROM} √† l‚Äô√©poque {start_epoch}.")

    history: Dict[str, list] = {"train_loss": [], "val_loss": [], "val_acc": []}
    no_improve_epochs = 0

    for epoch in range(start_epoch, EPOCHS):
        model.train()
        running_loss = 0.0
        ema = None

        pbar = tqdm(train_dl, desc=f"√âpoque {epoch+1}/{EPOCHS}")
        for step, (x, y) in enumerate(pbar):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad(set_to_none=True)

            logits = model(x)
            loss = criterion(logits, y)
            loss.backward()

            if GRAD_CLIP_NORM is not None and GRAD_CLIP_NORM > 0:
                nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRAD_CLIP_NORM)

            optimizer.step()

            # Scheduler plateau par it√©ration (sur loss brute ou EMA)
            loss_val = loss.item()
            if USE_EMA:
                ema = loss_val if ema is None else EMA_ALPHA * loss_val + (1 - EMA_ALPHA) * ema
                plateau.step(float(ema))
            else:
                plateau.step(loss_val)

            running_loss += loss_val
            cur_lr = optimizer.param_groups[0]["lr"]
            pbar.set_postfix(loss=f"{loss_val:.4f}", lr=f"{cur_lr:.2e}")

        train_loss = running_loss / max(1, len(train_dl))
        val_loss, val_acc = evaluate(model, val_dl, device, criterion)

        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        history["val_acc"].append(val_acc)

        print(f"‚úÖ √âpoque {epoch+1}/{EPOCHS} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.2f}%")

        # Sauvegarde ‚Äúbest‚Äù si am√©lioration val_loss
        improved = val_loss < best_val_loss - 1e-4
        if improved:
            best_val_loss = val_loss
            best_val_acc = max(best_val_acc, val_acc)
            save_light(CKPT_BEST, model, optimizer, epoch, best_val_loss, best_val_acc)
            print(f"üíæ Nouveau meilleur mod√®le ‚Üí {CKPT_BEST} | val_loss={best_val_loss:.4f} | best_acc={best_val_acc:.2f}%")
            no_improve_epochs = 0
        else:
            no_improve_epochs += 1

        # Early stopping sur val_loss
        if no_improve_epochs >= EARLY_STOP_PATIENCE:
            print(f"‚èπÔ∏è Early stopping (patience={EARLY_STOP_PATIENCE})")
            break

    # Sauvegarde ‚Äúlast‚Äù
    last_epoch = start_epoch + len(history["train_loss"]) - 1
    save_light(CKPT_LAST, model, optimizer, last_epoch, best_val_loss, best_val_acc)
    print(f"üíæ Checkpoint final (last) ‚Üí {CKPT_LAST}")

    # R√©sum√©
    print("\n=== R√âSUM√â ===")
    print(f"Meilleure val_loss: {best_val_loss:.4f} | Meilleure val_acc: {best_val_acc:.2f}%")
    print(f"Derni√®re train_loss: {history['train_loss'][-1]:.4f}")
    print(f"Derni√®re val_loss:   {history['val_loss'][-1]:.4f} | val_acc: {history['val_acc'][-1]:.2f}%")

if __name__ == "__main__":
    train()
