#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import sys
import time
import json
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import torch
from torch import nn
import torch.nn.functional as F
import torchvision.transforms as T
from torchvision import models
from PIL import Image

# YOLO (ultralytics)
try:
    from ultralytics import YOLO
except Exception as e:
    YOLO = None

# =========================
# Config utilisateur
# =========================
# Chemins (√† adapter)
MODEL_YOLO_PATH = "/Users/a.cariven/Documents/USAFA/comp scien/final-project-aymeric-et-louis/demos/yolov8n.pt"            # si vous avez un .pt ultralytics, mettez le .pt (ex: "yolov8n.pt")
MODEL_RESNET_PATH = "/Users/a.cariven/Documents/USAFA/comp scien/final-project-aymeric-et-louis/demos/resnet_model_optimized.pth"
IMAGE_PATH = "/Users/a.cariven/Documents/USAFA/comp scien/final-project-aymeric-et-louis/demos/inputs/rafale.jpg"

# Optionnel: liste des classes (si vous avez un fichier JSON/texte)
# Si None, on essaiera de la tirer du checkpoint (cl√© 'classes' si pr√©sente)
CLASSES: Optional[List[str]] = None  # par exemple: ["A320", "A330", ...] (taille 95)

# Seuils
YOLO_CONF_THRES = 0.25
YOLO_IOU_THRES = 0.45

# Tailles d'entr√©e ResNet
RESNET_INPUT_SIZE = 224

data_dir = "/Users/a.cariven/Documents/USAFA/comp scien/final-project-aymeric-et-louis/demos/crop"

CLASSES = sorted([
        d for d in os.listdir(data_dir)
        if os.path.isdir(os.path.join(data_dir, d)) and not d.startswith('.')
    ])

# =========================
# Gestion des devices
# =========================
def get_device_labels():
    device_yolo = "cpu"  # impos√© par la demande
    device_resnet = "mps" if torch.backends.mps.is_available() else ("cuda" if torch.cuda.is_available() else "cpu")
    return device_yolo, device_resnet

# =========================
# Utils
# =========================
def log(s: str):
    print(s, flush=True)

def timeit(fn):
    def wrapper(*args, **kwargs):
        t0 = time.time()
        res = fn(*args, **kwargs)
        dt = (time.time() - t0) * 1000
        log(f"‚è±Ô∏è  {fn.__name__} termin√© en {dt:.1f} ms")
        return res
    return wrapper

def ensure_exists(path: str, kind: str = "fichier"):
    if not os.path.exists(path):
        raise FileNotFoundError(f"Le {kind} '{path}' est introuvable.")

# =========================
# Pr√©-traitements ResNet
# =========================
def build_resnet_transform(img_size: int = 224):
    return T.Compose([
        T.Resize((img_size, img_size)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
    ])

# =========================
# Chargeur ResNet auto-d√©tectant
# =========================
def _strip_prefix(state_dict, prefixes=("module.", "model.")):
    new_sd = {}
    for k, v in state_dict.items():
        for p in prefixes:
            if k.startswith(p):
                k = k[len(p):]
        new_sd[k] = v
    return new_sd

def _is_bottleneck(state_keys):
    # Bottleneck ‚áí pr√©sence de conv3 dans les blocs
    return any("layer1.0.conv3.weight" in k for k in state_keys)

def _infer_layout(state_keys):
    # Estime le nombre de blocs par layer via les index pr√©sents
    def count_blocks(layer):
        pattern = re.compile(rf"^{layer}\.(\d+)\.")
        idx = set()
        for k in state_keys:
            m = pattern.match(k)
            if m:
                idx.add(int(m.group(1)))
        return (1 + max(idx)) if idx else 0
    return tuple(map(count_blocks, ["layer1", "layer2", "layer3", "layer4"]))

def _build_matching_resnet(state_dict, num_classes_hint=None):
    state_dict = _strip_prefix(state_dict)
    keys = list(state_dict.keys())

    is_bottleneck = _is_bottleneck(keys)
    layout = _infer_layout(keys)  # e.g., (2,2,2,2) / (3,4,6,3) / (3,8,36,3)

    # Nb classes depuis fc.weight si possible
    num_classes_ckpt = None
    if "fc.weight" in state_dict and isinstance(state_dict["fc.weight"], torch.Tensor):
        num_classes_ckpt = state_dict["fc.weight"].shape[0]
    num_classes = num_classes_hint or num_classes_ckpt or 1000

    # Choix mod√®le
    if is_bottleneck:
        # 50/101/152 (fc.in_features=2048)
        if layout == (3,4,6,3):
            model = models.resnet50(weights=None)
        elif layout == (3,4,23,3):
            model = models.resnet101(weights=None)
        elif layout == (3,8,36,3):
            model = models.resnet152(weights=None)
        else:
            model = models.resnet50(weights=None)
        in_feats = model.fc.in_features
    else:
        # 18/34 (fc.in_features=512)
        if layout == (2,2,2,2):
            model = models.resnet18(weights=None)
        elif layout == (3,4,6,3):
            model = models.resnet34(weights=None)
        else:
            model = models.resnet34(weights=None)
        in_feats = model.fc.in_features

    # Adapter la couche finale pour charger correctement fc
    model.fc = nn.Linear(in_feats, num_classes)
    return model, state_dict, num_classes

def _extract_state_dict(ckpt_obj):
    # Supporte formats: state_dict direct, ou dict avec 'state_dict'
    if isinstance(ckpt_obj, dict):
        if "state_dict" in ckpt_obj:
            return ckpt_obj["state_dict"], ckpt_obj.get("classes", None)
        # certains exports utilisent 'model' ou 'net'
        for k in ("model", "net"):
            if k in ckpt_obj and hasattr(ckpt_obj[k], "state_dict"):
                return ckpt_obj[k].state_dict(), ckpt_obj.get("classes", None)
    return ckpt_obj, None

@timeit
def load_resnet_autodetect(model_path: str, classes: Optional[List[str]], device: str):
    ensure_exists(model_path, "checkpoint ResNet")
    ckpt = torch.load(model_path, map_location="cpu")
    state_dict, classes_in_ckpt = _extract_state_dict(ckpt)

    # classes hint
    num_classes_hint = len(classes) if isinstance(classes, list) else None
    model, state_dict, num_classes = _build_matching_resnet(state_dict, num_classes_hint)

    if classes_in_ckpt is not None and isinstance(classes_in_ckpt, (list, tuple)):
        if classes is None:
            classes = list(classes_in_ckpt)
        elif len(classes) != len(classes_in_ckpt):
            log(f"‚ö†Ô∏è Liste de classes fournie ({len(classes)}) ‚â† checkpoint ({len(classes_in_ckpt)}). "
                f"On conserve la dimension du checkpoint pour charger fc.")

    log(f"‚ÑπÔ∏è ResNet d√©tect√©: "
        f"{'Bottleneck' if model.layer1[0].expansion==4 else 'BasicBlock'} | "
        f"fc.in_features={model.fc.in_features} | classes={num_classes}")

    # Chargement strict
    model.load_state_dict(state_dict, strict=True)
    model.eval()
    model.to(device)
    return model, classes

# =========================
# Chargement YOLO (CPU)
# =========================
@timeit
def load_yolo(model_path: str, device: str = "cpu"):
    if YOLO is None:
        raise RuntimeError("ultralytics n'est pas install√©. Installez-le avec: pip install ultralytics")
    ensure_exists(model_path, "mod√®le YOLO")
    # ultralytics supporte .pt/.onnx. Le 'device' est g√©r√© √† l'inf√©rence.
    model = YOLO(model_path)
    return model

# =========================
# Inference helpers
# =========================
def yolo_detect(yolo_model, image_path: str, conf: float, iou: float) -> List[Dict[str, Any]]:
    results = yolo_model.predict(
        source=image_path,
        device="cpu",
        conf=conf,
        iou=iou,
        verbose=False
    )
    dets = []
    if not results:
        return dets
    r0 = results[0]
    if r0.boxes is None or len(r0.boxes) == 0:
        return dets
    boxes = r0.boxes.xyxy.cpu().numpy()
    scores = r0.boxes.conf.cpu().numpy()
    cls_ids = r0.boxes.cls.cpu().numpy() if r0.boxes.cls is not None else None
    for i in range(len(boxes)):
        x1, y1, x2, y2 = [int(v) for v in boxes[i]]
        dets.append({
            "bbox": (x1, y1, x2, y2),
            "score": float(scores[i]),
            "cls_id": int(cls_ids[i]) if cls_ids is not None else -1
        })
    return dets

def crop_image(pil_img: Image.Image, bbox: Tuple[int, int, int, int]) -> Image.Image:
    x1, y1, x2, y2 = bbox
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(pil_img.width, x2), min(pil_img.height, y2)
    return pil_img.crop((x1, y1, x2, y2))

def classify_topk(model_resnet,
                  device: str,
                  crops: List[Image.Image],
                  classes: Optional[List[str]],
                  img_size: int = 224,
                  k: int = 3) -> List[List[Dict[str, Any]]]:
    """
    Retourne pour chaque crop une liste (tri√©e desc) des k meilleures classes:
    [
      [ {"label": str, "prob": float, "class_id": int}, ... (k) ],
      ...
    ]
    """
    if len(crops) == 0:
        return []

    tfm = build_resnet_transform(img_size)
    with torch.no_grad():
        batch = torch.stack([tfm(im) for im in crops]).to(device)  # [N,3,H,W]
        logits = model_resnet(batch)                                # [N,C]
        probs = F.softmax(logits, dim=1)                            # [N,C]
        k = min(k, probs.shape[1])
        top_p, top_i = torch.topk(probs, k=k, dim=1)                # [N,k], [N,k]

    results: List[List[Dict[str, Any]]] = []
    for p_row, i_row in zip(top_p.cpu(), top_i.cpu()):
        entries = []
        for p, idx in zip(p_row.tolist(), i_row.tolist()):
            label = classes[idx] if (classes and 0 <= idx < len(classes)) else f"class_{idx}"
            entries.append({"label": label, "prob": float(p), "class_id": int(idx)})
        results.append(entries)
    return results

@timeit
def analyser_image(image_path: str,
                   yolo_model,
                   resnet_model,
                   classes: Optional[List[str]],
                   device_resnet: str,
                   conf: float = 0.25,
                   iou: float = 0.45,
                   resnet_img_size: int = 224,
                   topk: int = 3):
    ensure_exists(image_path, "image")
    img = Image.open(image_path).convert("RGB")

    # 1) D√©tection
    detections = yolo_detect(yolo_model, image_path, conf, iou)

    if len(detections) == 0:
        return []

    # 2) Rognage + classification Top-k
    crops = [crop_image(img, det["bbox"]) for det in detections]
    topk_per_crop = classify_topk(resnet_model, device_resnet, crops, classes, resnet_img_size, k=topk)

    # 3) Fusion r√©sultats
    outputs = []
    for det, topk_list in zip(detections, topk_per_crop):
        outputs.append({
            "coordonnees": det["bbox"],
            "confiance_detection": det["score"],
            "topk": topk_list  # liste de dicts: [{"label","prob","class_id"}, ...]
        })
    return outputs

# =========================
# Main
# =========================
def main():
    device_yolo, device_resnet = get_device_labels()
    log(f"üîß Configuration mat√©rielle - YOLO: {device_yolo}, ResNet: {device_resnet}")
    try:
        # Chargement YOLO (CPU)
        if MODEL_YOLO_PATH.lower().endswith(".pt") or MODEL_YOLO_PATH.lower().endswith(".onnx"):
            yolo_model = load_yolo(MODEL_YOLO_PATH, device=device_yolo)
        else:
            raise ValueError("Fournissez un mod√®le YOLO .pt ou .onnx valide.")

        # Chargement ResNet (MPS si dispo)
        log("üîÑ Chargement du mod√®le ResNet...")
        resnet_model, classes = load_resnet_autodetect(MODEL_RESNET_PATH, CLASSES, device=device_resnet)

        if classes is None:
            # Si aucune liste fournie ni trouv√©e, on cr√©e des √©tiquettes num√©riques
            out_dim = resnet_model.fc.out_features
            classes = [f"class_{i}" for i in range(out_dim)]
            log(f"‚ÑπÔ∏è Aucune liste de classes fournie/trouv√©e, on utilise {out_dim} labels g√©n√©riques.")

        # Inference (avec Top-3)
        results = analyser_image(
            IMAGE_PATH,
            yolo_model,
            resnet_model,
            classes,
            device_resnet,
            conf=YOLO_CONF_THRES,
            iou=YOLO_IOU_THRES,
            resnet_img_size=RESNET_INPUT_SIZE,
            topk=3
        )

        if results:
            log("\nüìã R√©sultats:")
            for i, r in enumerate(results, 1):
                x1, y1, x2, y2 = r["coordonnees"]
                log(f"\nüõ©Ô∏è Objet {i}:")
                log(f"   Coordonn√©es: ({x1}, {y1}, {x2}, {y2})")
                log(f"   Confiance YOLO: {r['confiance_detection']:.3f}")
                for rank, cand in enumerate(r["topk"], 1):
                    log(f"   #{rank} {cand['label']} ‚Äî p={cand['prob']:.4f} (id={cand['class_id']})")
        else:
            log("‚ö†Ô∏è Aucun objet d√©tect√© par YOLO.")

    except Exception as e:
        # On tente d‚Äô√™tre explicite sur les erreurs fr√©quentes
        msg = str(e)
        if "Missing key(s) in state_dict" in msg or "size mismatch" in msg:
            log("‚ùå Erreur fatale: ‚ùå Erreur dans analyser_image: ‚ùå Erreur chargement ResNet: " + msg)
        elif "ultralytics n'est pas install√©" in msg:
            log("‚ùå Ultralytics manquant. Installez-le: pip install ultralytics")
        else:
            log("‚ùå Erreur fatale: " + msg)

if __name__ == "__main__":
    main()
